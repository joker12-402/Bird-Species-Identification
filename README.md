# Bird Species Identification
基于深度学习的鸟类声纹识别系统：多特征融合与注意力机制的实践

## 项目简介
本项目旨在构建高性能的鸟类声纹识别系统，通过融合多种声学特征与引入注意力机制，实现对鸟类物种的精准识别。系统针对鸟类声音的时频特性，设计了多套深度学习模型架构，最终在公开/自定义数据集上取得了**94.78%** 的识别准确率，为鸟类监测、生态保护等场景提供技术支撑。


## 项目结构
```
Bird_Species_Identification/
├── src/                  # 核心源代码目录
│   ├── model_150.py      # 基线模型（MFCC特征单输入）
│   ├── model_a_150.py    # Model A（MFCC + 时域特征融合）
│   ├── model_b_150.py    # Model B（MFCC + 能量特征融合）
│   ├── model_c_no_attention.py  # Model C（无注意力机制，多特征基础版）
│   ├── 20.model_c_v8.py  # Model C（带注意力机制，当前最佳模型）
│   ├── 21.model_c_v9.py  # Model C（多尺度卷积 + 双端注意力增强版）
│   ├── 22.model_c_v10.py # Model C（简化版多尺度卷积，轻量化适配）
│   └── ...               # 其他模型迭代版本
├── data/                 # 数据目录（注：因数据量大，需与项目根目录同级存放）
│   └── processed_audio/  # 预处理后的音频数据存放路径
├── results/              # 实验结果目录（注：因文件体积大，需与项目根目录同级存放）
│   ├── training_history/ # 各模型训练损失、准确率等日志（JSON格式）
│   ├── model_weights/    # 训练完成的模型权重文件
│   └── evaluation/       # 测试集性能评估报告（准确率、F1分数等）
└── README.md             # 项目说明文档
```


## 核心技术特点
### 1. 多维度特征融合
突破单一特征的局限性，联合提取鸟类声纹的关键声学特征：
- **MFCC特征**：捕捉声音的时频纹理信息，反映鸟类叫声的频谱结构；
- **时域特征**：保留声音的原始时序动态，捕捉叫声的节奏与持续特性；
- **能量特征**：刻画声音的强度变化，辅助区分相似频率的不同物种叫声。

### 2. 注意力机制优化
在最佳模型中引入注意力模块，实现「特征自适应加权」：
- 自动学习不同特征维度对识别任务的重要性，抑制噪声特征干扰；
- 聚焦于鸟类叫声的关键片段（如鸣唱主峰），提升模型抗干扰能力。

### 3. 多尺度卷积设计
针对不同鸟类叫声的频率跨度差异，设计多尺度卷积架构：
- 采用不同尺寸的卷积核提取细粒度与粗粒度时频特征；
- 平衡「局部细节捕捉」与「全局模式识别」，适配多样的鸟类声纹特性。


## 实验结果
### 核心性能指标
| 模型名称                | 识别准确率 | 核心改进点                  |
|-------------------------|------------|-----------------------------|
| 基线模型（model_150）   | 92.18%     | MFCC单特征 baseline         |
| Model A（MFCC+时域）    | 92.92%     | 新增时域特征融合            |
| Model B（MFCC+能量）    | 94.60%     | 新增能量特征融合            |
| Model C（无注意力）     | 94.22%     | 多特征融合基础架构          |
| **Model C（带注意力）** | **94.78%** | 多特征融合 + 注意力机制（最佳） |

### 结果可视化
实验结果包含各模型的训练曲线（损失/准确率）、混淆矩阵、特征重要性热力图等，均存放于 `results/evaluation/` 目录下，可直观对比模型性能与改进效果。


## 快速开始
### 1. 环境准备
#### 1.1 依赖安装
首先克隆项目并安装所需依赖：
```bash
# 克隆仓库（示例）
git clone https://github.com/your-username/Bird-Species-Identification.git
cd Bird-Species-Identification

# 安装依赖
pip install -r requirements.txt
```

#### 1.2 依赖清单
- Python 3.6+
- 核心库：numpy, pandas, librosa（音频特征提取）
- 深度学习：torch/tensorflow（根据模型实现选择）
- 可视化：matplotlib, seaborn（训练曲线与结果分析）
- 工具库：json, os, argparse（日志与参数解析）

### 2. 数据准备
1. 将原始音频数据（支持.wav/.mp3格式）预处理为统一采样率（建议16kHz）；
2. 将预处理后的音频文件放入 `data/processed_audio/` 目录，目录结构建议按物种分类：
   ```
   data/processed_audio/
   ├── Species_A/
   │   ├── audio_1.wav
   │   └── audio_2.wav
   ├── Species_B/
   │   └── ...
   └── ...
   ```

### 3. 模型训练与测试
#### 3.1 训练最佳模型
运行带注意力机制的Model C（当前性能最优）：
```bash
python src/20.model_c_v8.py
```
- 训练日志会自动保存至 `results/training_history/model_c_v8.json`；
- 训练完成的模型权重会保存至 `results/model_weights/model_c_v8.pth`。

#### 3.2 测试与推理
在模型文件中已集成测试逻辑，训练完成后会自动在测试集上评估性能；若需单独推理，可在模型文件中调用 `infer(audio_path)` 函数，传入音频路径即可输出物种预测结果。


## 模型迭代说明
本项目采用「增量迭代」的模型设计思路，各版本演进逻辑如下：
1. **基线模型**：验证MFCC特征的基础有效性；
2. **Model A/B**：分别验证时域/能量特征的补充价值；
3. **Model C基础版**：融合三种特征，搭建多输入基础架构；
4. **Model C增强版**：引入注意力机制、多尺度卷积，逐步提升性能；
5. **Model C轻量化版**：简化架构以适配资源受限场景（如边缘设备）。


## 注意事项
1. 数据存放：`data/` 和 `results/` 目录因体积较大，需手动创建并与项目根目录同级存放；
2. 特征提取：若需重新提取特征，可在模型文件中调用 `librosa` 相关函数，参数已预设最优配置；
3. 超参数调整：训练脚本支持通过命令行参数调整学习率、批次大小等，可运行 `python src/20.model_c_v8.py -h` 查看参数说明。


## 致谢
感谢 [Librosa](https://librosa.org/doc/latest/index.html) 音频处理库、PyTorch/TensorFlow 深度学习框架对本项目的技术支撑，同时感谢相关鸟类声纹数据集提供方的开源贡献。

---
**项目维护者**：陈钰鑫
**联系方式**：1091874554@qq.com  
**更新时间**：2025年9月16日
- PyTorch 1.8+
- Librosa
- Scikit-learn

## 许可证
本项目采用 [MIT 许可证](LICENSE) 开源，允许自由使用、修改和分发。
